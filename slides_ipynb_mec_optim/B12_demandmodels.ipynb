{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Block 12: Demand models, old and new</center>\n",
    "### <center>Alfred Galichon (NYU)</center>\n",
    "## <center>`math+econ+code' masterclass on matching models, optimal transport and applications</center>\n",
    "<center>Â© 2018-2019 by Alfred Galichon. Support from NSF grant DMS-1716489 is acknowledged. James Nesbit contributed.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning objectives\n",
    "\n",
    "* Beyond GEV: the pure characteristics models, the random coefficient logit model, the probit model\n",
    "\n",
    "* Simulation methods: Accept-Reject and SARS\n",
    "\n",
    "* Demand inversion (ctd): The inversion theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "* [OTME], Ch. 9.2\n",
    "\n",
    "* McFadden (1981). \"Econometric Models of Probabilistic Choice\", in C.F. Manski and D. McFadden (eds.), *Structural analysis of discrete data with econometric applications*, MIT Press.\n",
    "\n",
    "* Berry, Levinsohn, and Pakes (1995). \"Automobile Prices in Market Equilibrium,\" *Econometrica*.\n",
    "\n",
    "* Train. (2009). *Discrete Choice Methods with Simulation*. 2nd Edition. Cambridge University Press.\n",
    "\n",
    "* Galichon and Salanie (2017). \"Cupid's Invisible Hands\". Preprint.\n",
    "\n",
    "* Bonnet, G and Shum (2017). \"Yogurts choose consumers? Identification of Random Utility Models via Two-Sided Matching\". Working paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choice models beyond GEV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The need for further models\n",
    "\n",
    "The GEV models are convenient analytically, but not very flexible.\n",
    "\n",
    "The logit model imposes zero correlation across alternatives\n",
    "\n",
    "The nested logit allows for nonzero correlation, but in a very rigid way (needs to define nests).\n",
    "\n",
    "A good example is the probit model, where $\\varepsilon$ is a Gaussian vector. For this model, there is no close-form solution neither for $G$ nor for $G^*$.\n",
    "\n",
    "More recently, a number of modern models don't have closed-form either. These models require simulation methods in order to approximate them by discrete models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The pure characteristics model\n",
    "\n",
    "#### Motivation\n",
    "\n",
    "The pure characteristics model (Berry and Pakes, 2007) can be motivated as follows. Assume $y$ stands for the number of bedrooms. The logit model would assume that the random utility associated with a 2-BR is uncorrelated with a 3-BR, which is not realistic.\n",
    "\n",
    "Let $\\xi_{y}$ is the typical size of a bedroom of size $y$, one may introduce $\\epsilon$ as the valuation of size; in which case the utility shock associated with $y$ should be $\\varepsilon_{y}=\\epsilon\\xi_{y}$. More generally, the characteristics $\\xi_{y}$ is a $d$-dimensional (deterministic) vector, and $\\epsilon\\sim\\mathbf{P}_{\\epsilon}$ is a (random) vector of the same size standing for the valuations of the respective dimensions, so that\n",
    "\n",
    "\\begin{align*}\n",
    "\\varepsilon_{y}=\\epsilon^{\\intercal}\\xi_{y}.\n",
    "\\end{align*}\n",
    "\n",
    "For example, if each alternative $y$ stands for a model of car, the first component of $\\xi_{y}$ may be the price of car $y$; the other components may be other characteristics such as number of seats, fuel efficiency, size, etc. In that case, for a given dimension $y\\in\\mathcal{Y}_{0}$, $\\epsilon_{y}$ is the (random) valuation of this dimension by the consumer with taste vector $\\epsilon$.\n",
    "\n",
    "#### Definition\n",
    "\n",
    "Assume without loss of generality that $\\varepsilon_{y}=0$, that is $\\xi_{0}=0$ as we can always reduce the setting to this case by replacing $\\xi_{y}$ by $\\xi_{y}-\\xi_{0}$.\n",
    "\n",
    "Letting $Z$ be the $\\left\\vert \\mathcal{Y}\\right\\vert \\times d\\,$\\ matrix of $\\left(  y,k\\right)  $-term $\\xi_{y}^{k}$, this rewrites as\n",
    "\n",
    "\\begin{align*}\n",
    "\\varepsilon = Z\\epsilon.\n",
    "\\end{align*}\n",
    "\n",
    "Hence, we have\n",
    "\n",
    "\\begin{align*}\n",
    "G\\left(  U\\right)  =\\mathbb{E}\\left[  \\max\\left\\{  U+Z\\epsilon,0\\right\\}\\right].\n",
    "\\end{align*}\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{align*}\n",
    "\\sigma_{y}\\left(  U\\right)  =\\Pr\\left(  U_{y}-U_{z}\\geq\\left(  Z\\epsilon\\right)_{y}-\\left(  Z\\epsilon\\right)_{z}, \\quad forall z\\in\\mathcal{Y}_{0}\\backslash\\left\\{  y\\right\\}  \\right).\n",
    "\\end{align*}\n",
    "\n",
    "#### In dimension 1\n",
    "\n",
    "When $d=1$ (scalar characteristics), one has $\\sigma_{y}\\left(U\\right)  =\\Pr\\left(  U_{y}-U_{z}\\geq\\left(  \\xi_{y}-\\xi_{z}\\right)\\epsilon~\\forall z\\in\\mathcal{Y}_{0}\\backslash\\left\\{  y\\right\\}  \\right)  $, and thus\n",
    "\n",
    "\\begin{align*}\n",
    "\\sigma_{y}\\left(  U\\right)  =\\Pr\\left(  \\max_{z:\\xi_{y}>\\xi_{z}}\\left\\{\\frac{U_{y}-U_{z}}{\\xi_{y}-\\xi_{z}}\\right\\}  \\leq\\epsilon\\leq\\min_{z:\\xi_{y}<\\xi_{z}}\\left\\{  \\frac{U_{y}-U_{z}}{\\xi_{y}-\\xi_{z}}\\right\\}  \\right)\n",
    "\\end{align*}\n",
    "\n",
    "with the understanding that $\\max_{z\\in\\emptyset}f_{z}=-\\infty$ and \n",
    "$\\min_{z\\in\\emptyset}f_{z}=+\\infty$.\n",
    "\n",
    "Therefore, letting $\\mathbf{F}_{\\epsilon}$ be the c.d.f. associated with the distribution of $\\epsilon$, one has a closed-form expression for $\\sigma_{y}$:\n",
    "\n",
    "\\begin{align*}\n",
    "\\sigma_{y}\\left(  U\\right)  =\\mathbf{F}_{\\epsilon}\\left(  \\left[  \\max_{z:\\xi_{y}>\\xi_{z}}\\left\\{  \\frac{U_{y}-U_{z}}{\\xi_{y}-\\xi_{z}}\\right\\},\\min_{z:\\xi_{y}<\\xi_{z}}\\left\\{  \\frac{U_{y}-U_{z}}{\\xi_{y}-\\xi_{z}}\\right\\}\\right]  \\right)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The probit model\n",
    "\n",
    "When $\\mathbf{P}_{\\epsilon}$ is the $\\mathcal{N}\\left(  0,S\\right)  $\n",
    "distribution, then the pure characteristics model is called a Probit model; in this case,\n",
    "\n",
    "\\begin{align*}\n",
    "\\varepsilon\\sim\\mathcal{N}\\left(  0,\\Sigma\\right)  \\text{ where }%\n",
    "\\Sigma=ZSZ^{\\intercal}.\n",
    "\\end{align*}\n",
    "\n",
    "Note the distribution $\\varepsilon\\,$will not have full support unless $d\\geq\\left\\vert \\mathcal{Y}\\right\\vert $ and $Z$ is of full rank.\n",
    "\n",
    "Computing $\\sigma$ in the Probit model thus implies computing the mass assigned by the Gaussian distribution to rectangles of the type \n",
    "\n",
    "\\begin{align*}\n",
    "\\left[  l_{y},u_{y}\\right]  .\n",
    "\\end{align*}\n",
    "\n",
    "When $\\Sigma$ is diagonal (random utility terms are i.i.d. across alternatives), this is numerically easy. However, this is computationally difficult in general (more on this later)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The random coefficient logit model\n",
    "\n",
    "The random coefficient logit model (Berry, Levinsohn and Pakes, 1995) may be viewed as an interpolant between the random characteristics model and the logit model. In this case,\n",
    "\n",
    "\\begin{align*}\n",
    "\\varepsilon=\\left(  1-\\lambda\\right)  Z\\epsilon+\\lambda\\eta\n",
    "\\end{align*}\n",
    "\n",
    "where $\\epsilon\\sim\\mathbf{P}_{\\epsilon}$, $\\eta$ is an EV1 distribution independent from the previous term, and $\\lambda$ is a interpolation parameter ($\\lambda=1$ is the logit model, and $\\lambda=0$ is the pure characteristics model).\n",
    "\n",
    "In this case, one may compute the Emax operator as \n",
    "\n",
    "\\begin{align*}\n",
    "G\\left(  U\\right)   &  =\\mathbb{E}\\left[  \\max_{y\\in\\mathcal{Y}_{0}}\\left\\{U_{y}+\\left(  1-\\lambda\\right)  \\left(  Z\\epsilon\\right)  _{y}+\\lambda\\eta_{y}\\right\\}  \\right] \\\\\n",
    "& =\\mathbb{E}\\left[  \\mathbb{E}\\left[  \\max_{y\\in\\mathcal{Y}_{0}}\\left\\{U_{y}+\\left(  1-\\lambda\\right)  \\left(  Z\\epsilon\\right)  _{y}+\\lambda\\eta_{y}\\right\\}  |\\epsilon\\right]  \\right] \\\\\n",
    "&  =\\mathbb{E}\\left[  \\lambda\\log\\sum_{y\\in\\mathcal{Y}_{0}}\\exp\\left(\n",
    "\\frac{U_{y}+\\left(  1-\\lambda\\right)  \\left(  Z\\epsilon\\right)  _{y}}{\\lambda}\\right)  \\right]\n",
    "\\end{align*}\n",
    "\n",
    "Recall\n",
    "\n",
    "\\begin{align*}\n",
    "G\\left(  U\\right)  =\\mathbb{E}\\left[  \\lambda\\log\\sum_{y\\in\\mathcal{Y}_{0}}\\exp\\left(  \\frac{U_{y}+\\left(  1-\\lambda\\right)  \\left(  Z\\epsilon\\right){y}}{\\lambda}\\right)  \\right]  .\n",
    "\\end{align*}\n",
    "\n",
    "The demand map in the random coefficients logit model is obtained by derivation of the expression of the Emax, i.e.\n",
    "\n",
    "\\begin{align*}\n",
    "\\sigma_{y}\\left(  U\\right)  =\\mathbb{E}\\left[  \\frac{\\exp\\left(  \\frac{U_{y}+\\left(  1-\\lambda\\right)  \\left(  Z\\epsilon\\right)  _{y}}{\\lambda}\\right)  }{\\sum_{y^{\\prime}\\in\\mathcal{Y}_{0}}\\exp\\left(  \\frac{U_{y^{\\prime}}+\\left(  1-\\lambda\\right)  \\left(  Z\\epsilon\\right)  _{y^{\\prime}}}{\\lambda}\\right)  }\\right]  .\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation methods\n",
    "\n",
    "In a number of cases, one cannot compute the choice probabilities $\\sigma\\left(  U\\right)$ using a closed-form expression. In this case, we need to resort to simulation to compute $G$, $G^{\\ast}$, $\\sigma$ and $\\sigma^{-1}$.\n",
    "\n",
    "The idea is that:\n",
    "\n",
    "* One is able to compute $G$ and $G^{\\ast}$ for discrete distributions (more on this later)\n",
    "\n",
    "* The sampled versions of $G$, $G^{\\ast}$, $\\sigma$ and $\\sigma^{-1}$ converge to the populations objects when the sample size is large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accept-reject simulator\n",
    "\n",
    "One simulates $N$ points $\\varepsilon^{i}\\sim P$. The Emax operator associated with the empirical sample distribution $P_{N}$ is\n",
    "\n",
    "\\begin{align*}\n",
    "G_{N}=N^{-1}\\sum_{i=1}^{N}\\max_{y\\in\\mathcal{Y}}\\left\\{  U_{y} + \\varepsilon_{y}^{i}\\right\\}\n",
    "\\end{align*}\n",
    "\n",
    "and the demand map is given by\n",
    "\n",
    "\\begin{align*}\n",
    "\\sigma_{N,y}\\left(  U\\right)  =N^{-1}\\sum_{i=1}^{N}1\\left\\{  U_{y} + \\varepsilon_{y}^{i}\\geq U_{z}+\\varepsilon_{z}^{i}, \\quad \\forall z\\in\\mathcal{Y}\n",
    "_{0}\\right\\}\n",
    "\\end{align*}\n",
    "\n",
    "In the literature, $\\sigma_{N}$ is called the *accept-reject simulator*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### McFadden's SARS\n",
    "\n",
    "McFadden's smoothed accept-reject simulator (SARS) consists in sampling $\\varepsilon\\sim P$: $\\varepsilon^{1},...,\\varepsilon^{N}$, and replacing the max by the smooth-max\n",
    "\n",
    "\\begin{align*}\n",
    "\\sigma_{N,T,y}\\left(  U\\right)  =\\sum_{i=1}^{N}\\frac{1}{N}\\frac{\\exp\\left((U_{y}+\\varepsilon_{y}^{i})/T\\right)  }{\\sum_{z}\\exp\\left(  (U_{z}+\\varepsilon_{z}^{i})/T\\right)}\n",
    "\\end{align*}\n",
    "\n",
    "One seeks $U$ so that the induced choice probabilities are $s$, that is\n",
    "\n",
    "\\begin{align*}\n",
    "s_{y}=\\sum_{i=1}^{N}\\frac{1}{N}\\frac{\\exp\\left(  (U_{y}+\\varepsilon_{y}^{i})/T\\right)  }{\\sum_{z}\\exp\\left(  (U_{z}+\\varepsilon_{z}^{i})/T\\right)}.\n",
    "\\end{align*}\n",
    "\n",
    "The associated Emax operator is\n",
    "\n",
    "\\begin{align*}\n",
    "G_{N,T}\\left(  U\\right)  =\\mathbb{E}_{\\mathbf{P}_{N}}\\left[G_{\\operatorname{logit}}\\left(  U+\\varepsilon^{i}\\right)  \\right]\n",
    "\\end{align*}\n",
    "\n",
    "so the underlying random utility structure is a random coefficient logit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The inversion theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Theorem** [Galichon and Salanie]\n",
    "\n",
    "Consider a solution $\\left(u\\left(  \\varepsilon\\right),v_{y}\\right)  $ to the dual Monge-Kantorovich problem with cost $\\Phi\\left(\\varepsilon,y\\right)  =\\varepsilon_{y}$, that is:\n",
    "\n",
    "<a name='MKDualDC'></a>\n",
    "\\begin{align*}\n",
    "\\min_{u,v}  &  \\int u\\left(  \\varepsilon\\right)  d\\mathbf{P}\\left(\n",
    "\\varepsilon\\right)  +\\sum_{y\\in\\mathcal{Y}_{0}}v_{y}s_{y}\\\\\n",
    "s.t.~  &  u\\left(  \\varepsilon\\right)  +v_{y}\\geq\\Phi\\left(  \\varepsilon\n",
    ",y\\right)\n",
    "\\end{align*}\n",
    "\n",
    "Then:\n",
    "\n",
    "* $U=\\sigma^{-1}\\left(  s\\right)  $ is given by $U_{y}=v_{0}-v_{y}$.\n",
    "\n",
    "* The value of the [MK dual](#MKDualDC) is $-G^{\\ast}\\left(  s\\right)  $.\n",
    "\n",
    "---\n",
    "---\n",
    "**Proof**\n",
    "\n",
    "$\\sigma^{-1}\\left(  s\\right)  =\\arg\\max_{U:U_{0}=0}\\left\\{  \\sum_{y\\in\\mathcal{Y}}s_{y}U_{y}-G(U)\\right\\}  $, thus, letting $v=-U$, $v$ is the solution to\n",
    "\n",
    "\\begin{align*}\n",
    "\\min_{v:v_{0}=0}\\left\\{  \\sum_{y\\in\\mathcal{Y}_{0}}s_{y}v_{y}+G(-v)\\right\\}\n",
    "\\end{align*}\n",
    "which is exactly the [MK dual](#MKDualDC).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inversion of the pure characteristics model\n",
    "\n",
    "It follows from the inversion theorem that the problem of demand inversion in the pure characteristics model is a semi-discrete transport problem, a point made in Bonnet, Galichon and Shum (2017).\n",
    "\n",
    "Indeed, the correspondence is:\n",
    "\n",
    "* an alternative $y$ is a fountain\n",
    "\n",
    "* the characteristics of an alternative is a fountain location\n",
    "\n",
    "* the systematic utility associated with alternative $y$ is minus the price of fountain $y$\n",
    "\n",
    "* the market share of altenative $y$ coindides with the capacity of fountain $y$\n",
    "\n",
    "* the random vector $\\epsilon$ is the location of an inhabitant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### McFadden's SARS and regularized Optimal Transport\n",
    "\n",
    "Cf. Bonnet, Galichon and Shum (2017). Let $u_{i}=T\\log\\sum_{z}\\exp\\left((U_{z}+\\varepsilon_{z}^{i})/T\\right)  $. One has\n",
    "\n",
    "\\begin{align*}\n",
    "\\left\\{\n",
    "\\begin{array}\n",
    "[c]{l}%\n",
    "s_{y}=\\sum_{i=1}^{N}\\frac{1}{N}\\exp\\left(  (U_{y}-u_{i}+\\varepsilon_{y}^{i})/T\\right) \\\\\n",
    "\\frac{1}{N}=\\sum_{y}\\frac{1}{N}\\exp\\left(  (U_{y}-u_{i}+\\varepsilon_{y}^{i})/T\\right)\n",
    "\\end{array}\n",
    "\\right. .\n",
    "\\end{align*}\n",
    "\n",
    "As a result, $\\left(  u_{i},U_{y}\\right)  $ are the solution of the regularized OT problem\n",
    "\n",
    "\\begin{align*}\n",
    "\\min_{u,U}\\sum_{i=1}^{N}\\frac{1}{N}u_{i}-\\sum s_{y}U_{y}+\\sum_{i,y}\\frac{1}{N}\\exp\\left(  (U_{y}-u_{i}+\\varepsilon_{y}^{i})/T\\right)  .\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLP's contraction mapping\n",
    "\n",
    "Consider the IPFP algorithm for solving the latter problem:\n",
    "\n",
    "\\begin{align*}\n",
    "\\left\\{\n",
    "\\begin{array}\n",
    "[c]{l}\n",
    "\\exp\\left(  u_{i}^{k+1}/T\\right)  =\\sum_{z}\\exp\\left(  (U_{z}^{k}%\n",
    "+\\varepsilon_{z}^{i})/T\\right) \\\\\n",
    "\\exp U_{y}^{k+1}/T=\\frac{Ns_{y}}{\\sum_{i=1}^{N}\\exp\\left(  (-u_{i}%\n",
    "^{k+1}+\\varepsilon_{y}^{i})/T\\right)  }\n",
    "\\end{array}\n",
    "\\right.\n",
    "\\end{align*}\n",
    "\n",
    "This rewrites as\n",
    "\n",
    "\\begin{align*}\n",
    "\\exp U_{y}^{k+1}/T  &  =\\frac{Ns_{y}}{\\sum_{i=1}^{N}\\frac{\\exp\\left(\n",
    "\\varepsilon_{y}^{i}/T\\right)  }{\\sum_{z}\\exp\\left(  (U_{z}^{k}+\\varepsilon\n",
    "_{z}^{i})/T\\right)  }},\\text{ i.e.}\\\\\n",
    "U_{y}^{k+1}  &  =T\\log s_{y}-T\\log\\sum_{i=1}^{N}\\frac{1}{N}\\frac{\\exp\\left(\n",
    "\\varepsilon_{y}^{i}/T\\right)  }{\\sum_{z}\\exp\\left(  (U_{z}^{k}+\\varepsilon\n",
    "_{z}^{i})/T\\right)  }\n",
    "\\end{align*}\n",
    "\n",
    "which is exactly the contraction mapping algorithm of Berry, Levinsohn and Pakes (1995, appendix 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall code the AR simulator for the probit model and then invert it using the inversion theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a vector of systematic utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(Matrix)\n",
    "library(gurobi)\n",
    "# seed = 777 set.seed(seed)\n",
    "U_y = c(0.4, 0.5, 0.2, 0.3, 0.1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate the market shares using the AR simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbDraws = 1e+04\n",
    "nbY = length(U_y)\n",
    "rho = 0.5\n",
    "\n",
    "Covar = rho * matrix(1, nbY, nbY) + (1 - rho) * diag(1, nbY)\n",
    "E = eigen(Covar)\n",
    "V = E$values\n",
    "Q = E$vectors\n",
    "SqrtCovar = Q %*% diag(sqrt(V)) %*% t(Q)\n",
    "epsilon_iy = matrix(rnorm(nbDraws * nbY), ncol = nbY) %*% SqrtCovar\n",
    "# \n",
    "u_iy = t(t(epsilon_iy) + U_y)\n",
    "ui = apply(X = u_iy, MARGIN = 1, FUN = max)\n",
    "s_y = apply(X = u_iy - ui, MARGIN = 2, FUN = function(v) (length(which(v == 0))))/nbDraws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To invert the market share, simply run the optimal assignment problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"U_y (true and recovered)\"\n",
      "[1] 0.4 0.5 0.2 0.3 0.1 0.0\n",
      "[1] 0.39998886 0.49999324 0.20000182 0.29998255 0.09999672 0.00000000\n"
     ]
    }
   ],
   "source": [
    "A1 = kronecker(matrix(1, 1, nbY), sparseMatrix(1:nbDraws, 1:nbDraws))\n",
    "A2 = kronecker(sparseMatrix(1:nbY, 1:nbY), matrix(1, 1, nbDraws))\n",
    "A = rbind2(A1, A2)\n",
    "result = gurobi(list(A = A, obj = c(epsilon_iy), modelsense = \"max\", rhs = c(rep(1/nbDraws, \n",
    "    nbDraws), s_y), sense = \"=\"), params = list(OutputFlag = 0))\n",
    "Uhat_y = -result$pi[(1 + nbDraws):(nbY + nbDraws)] + result$pi[(nbY + nbDraws)]\n",
    "\n",
    "print(\"U_y (true and recovered)\")\n",
    "print(U_y)\n",
    "print(Uhat_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLP Data\n",
    "\n",
    "Let's take a look through the data of the Berry, Levinsohn and Pakes (1995), often referred to as BLP.\n",
    "\n",
    "This data comes from the High Dimensional Metrics library (hdm) library. Instead of installing the package and retrieving the data (which takes a while because we need to compile these of the library), we will instead just load it up directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load(\"BLPdata.Rdata\")\n",
    "BLPData\n",
    "data = as.matrix(BLPData)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
