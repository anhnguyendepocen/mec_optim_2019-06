{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Block 10: Multinomial choice I. Demand inversion</center>\n",
    "### <center>Alfred Galichon (NYU)</center>\n",
    "## <center>`math+econ+code' masterclass on matching models, optimal transport and applications</center>\n",
    "<center>Â© 2018-2019 by Alfred Galichon. Support from NSF grant DMS-1716489 is acknowledged. James Nesbit contributed.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning objectives\n",
    "\n",
    "* Emax operator and generalized entropy of choice\n",
    "\n",
    "* The Daly-Zachary-Williams theorem\n",
    "\n",
    "* The GEV class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "* [OTME], App. E\n",
    "\n",
    "* McFadden (1981). \"Econometric Models of Probabilistic Choice\", in C.F. Manski and D. McFadden (eds.), *Structural Analysis of Discrete Data with Econometric Applications*, MIT Press.\n",
    "\n",
    "* McFadden (1989). \"A Method of Simulated Moments for Estimation of Discrete Response Models Without Numerical\n",
    "Integration\". *Econometrica*.\n",
    "\n",
    "* Berry, Levinsohn, and Pakes (1995). \"Automobile Prices in Market Equilibrium,\" *Econometrica*.\n",
    "\n",
    "* Train. (2009). *Discrete Choice Methods with Simulation*. 2nd Edition. Cambridge University Press.\n",
    "\n",
    "* Galichon and Salanie (2017). \"Cupid's Invisible Hands\". Preprint.\n",
    "\n",
    "* Chiong, G and Shum (2016), \"Duality in Discrete Choice Models\". *Quantitative Economics*, 2016.\n",
    "\n",
    "* Greene and Hensher (1997), *Multinomial Logit and Discrete Choice Models*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emax operators and demand maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete choice models\n",
    "\n",
    "\n",
    "Assume a consumer is facing a number of options $y\\in\\mathcal{Y}_{0}=\\mathcal{Y}\\cup\\left\\{  0\\right\\}$, where $y=0$ is a default option. The consumer is drawing a utility shock which is a vector $\\varepsilon =(\\varepsilon_{0},\\ldots,\\varepsilon_{\\left\\vert \\mathcal{Y}\\right\\vert })\\sim\\mathbf{P}$ such that the utility of option $y$ is $U_{y}+\\varepsilon _{y}$, while the outside option yields utility $\\varepsilon_{0}$.\n",
    "\n",
    "$U$ is called vector of *systematic utilities*; $\\varepsilon$ is called vector of *utility shocks*.\n",
    "\n",
    "We assume throughout that $\\mathbf{P}$ has a density with respect to the Lebesgue measure, and has full support.\n",
    "\n",
    "The preferred option is the one which attains the maximum in\n",
    "\n",
    "\\begin{align*}\n",
    "\\max_{y\\in\\mathcal{Y}}\\left\\{  U_{y}+\\varepsilon_{y},\\varepsilon_{0}\\right\\}.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demand Map\n",
    "\n",
    "\\item Let $s_{y}=\\sigma_{y}\\left(  U\\right)  $ be the probability of choosing option $y$, where $\\sigma$ is given by \n",
    "\n",
    "\\begin{align*}\n",
    "\\sigma_{y}\\left(  U\\right)  =\\Pr(U_{y}+\\varepsilon_{y}\\geq U_{z}+\\varepsilon_{z}\\mbox{ for all }z\\in\\mathcal{Y}_{0}).\n",
    "\\end{align*}\n",
    "\n",
    "The map $\\sigma$ is called *demand map*, and the vector $s$ is called vector of market shares, or vector of choice probabilities.\n",
    "\n",
    "Note that if $s=\\sigma(U)$, then $s_{y}>0$ for all $y\\in\\mathcal{Y}_{0}$ and $\\sum_{y\\in\\mathcal{Y}_{0}}s_{y}=1$.\n",
    "\n",
    "Note that because the distribution $\\mathbf{P}$ of $\\varepsilon$ is continuous, the probability of being indifferent between two options is zero, and hence we could have indifferently replaced weak preference $\\geq$ by strict preference $>$. Without this, choice probabilities may not have been well defined.\n",
    "\n",
    "### Properties\n",
    "\n",
    "* $\\sigma_{y}\\left(  U\\right)  $ is increasing in $U_{y}$.\n",
    "\n",
    "* $\\sigma_{y}\\left(  U\\right)  $ is weakly decreasing in $U_{y^{\\prime}}$ for $y^{\\prime}\\neq y$.\n",
    "\n",
    "* If one replaces $\\left(  U_{y}\\right)  $ by $\\left(  U_{y}+c\\right)  $, for a constant $c$, one has $\\sigma\\left(  U+c\\right)  =\\sigma\\left( U\\right)  .$\n",
    "\n",
    "### Normalization\n",
    "\n",
    "Because of the last property, we can normalize the utility of one of the alternatives. We will normalize the utility of the utility associated to $y=0$, and hence take\n",
    "\n",
    "\\begin{align*}\n",
    "U_{0}=0.\n",
    "\\end{align*}\n",
    "\n",
    "Thus in the sequel, $\\sigma$ will be seen as a mapping from $\\mathbb{R}^{\\mathcal{Y}}$ to the set of $\\left(  s_{y}\\right)_{y\\in \\mathcal{Y}}$ such that $s_{y}>0$ and $\\sum_{y\\in\\mathcal{Y}}s_{y}<1$, and the choice probability of alternative $y=0$ is recovered by\n",
    "\n",
    "\\begin{align*}\n",
    "s_{0}=1-\\sum_{y\\in\\mathcal{Y}}s_{y}.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Daly-Williams-Zachary theorem\n",
    "\n",
    "Define the expected indirect utility of consumers by\n",
    "\n",
    "\\begin{align*}\n",
    "G(U)=\\mathbb{E}\\left[  \\max_{y\\in\\mathcal{Y}}(U_{y}+\\varepsilon_{y}%\n",
    ",\\varepsilon_{0})\\right]\n",
    "\\end{align*}\n",
    "\n",
    "This is called *Emax operator*, a.k.a. *McFadden's surplus function*.\n",
    "\n",
    "As the expectation of the maximum of terms which are linear in $U$, $G$ is convex function in $U$ (strictly convex in fact), and\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial G}{\\partial U_{y}}(U)=\\Pr(U_{y}+\\varepsilon_{y}\\geq\n",
    "U_{z}+\\varepsilon_{z}\\mbox{ for all }z\\in\\mathcal{Y}_{0}).\n",
    "\\end{align*}\n",
    "\n",
    "But the right-hand side is simply the probability $s_{y}$ of choosing option $y$; therefore, we get:\n",
    "\n",
    "---\n",
    "**Theorem (Daly-Zachary-Williams)**\n",
    "\n",
    "The demand map $\\sigma$ is the gradient of the Emax operator $G$, that is\n",
    "\n",
    "<a name='eq:derGU'></a>\n",
    "\\begin{align*}\n",
    "\\sigma\\left(  U\\right)  =\\nabla G(U).\n",
    "\\end{align*}\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Logit\n",
    "\n",
    "Assume that $\\mathbf{P}$ is the distribution of i.i.d. *centered type $1$ extreme value* a.k.a. *centered Gumbel* terms, which has c.d.f.\n",
    "\n",
    "\\begin{align*}\n",
    "F\\left(  z\\right)  =\\exp\\left(  -\\exp\\left(  -x+\\gamma\\right)  \\right)\n",
    "\\end{align*}\n",
    "\n",
    "where $\\gamma=0.5772...$ (Euler's constant). The mean of this distribution is zero.\n",
    "\n",
    "Basic fact from extreme value theory: if $\\varepsilon_{1}$ ,...,$\\varepsilon_{n}$ are i.i.d. Gumbel distributions, then $\\max\\left\\{U_{y}+\\varepsilon_{y}\\right\\}  $ has the same distribution as $\\log\\left(\\sum_{y=1}^{n}\\exp U_{y}\\right)  +\\epsilon$, where $\\epsilon$ is also a Gumbel. (Proof of this fact later).\n",
    "\n",
    "Notes:\n",
    "\n",
    "* This distribution is sometimes called the \"Gumbel max\" distribution, to contrast it with the distribution of its opposite, which is then called *Gumbel min*.\n",
    "\n",
    "* The literature usually calls *standard Gumbel* the distribution with c.d.f. $\\exp\\left(-\\exp\\left(  -x\\right)  \\right)  $; but that distribution has mean $\\gamma$, which is why we slightly depart from the convention.\n",
    "\n",
    "The Emax operator associated with the logit model can be given in closed form as\n",
    "\n",
    "\\begin{align*}\n",
    "G(U)=\\log\\left(  1+\\sum_{y\\in\\mathcal{Y}}\\exp(U_{y})\\right)\n",
    "\\end{align*}\n",
    "\n",
    "where $s_{0}=1-\\sum_{y\\in\\mathcal{Y}}s_{y}$. This is called a *log-partition function*\n",
    "\n",
    "As a result, the choice probability of alternative $y$ is proportional to the exponential of the systematic utility associated with $U$, that is \n",
    "\n",
    "\\begin{align*}\n",
    "\\sigma_{y}\\left(  U\\right)  =\\frac{\\exp U_{y}}{1+\\sum_{y^{\\prime}%\n",
    "\\in\\mathcal{Y}}\\exp(U_{y^{\\prime}})}\n",
    "\\end{align*}\n",
    "\n",
    "which is called a *Gibbs distribution*.\n",
    "\n",
    "\\Assume that the random utility shock is scaled by a factor $T$. Then\n",
    "\n",
    "\\begin{align*}\n",
    "\\sigma_{y}\\left(  U\\right)  =\\frac{\\exp\\left(  U_{y}/T\\right)  }{1+\\sum_{y^{\\prime}\\in\\mathcal{Y}}\\exp(U_{y^{\\prime}}/T)}\n",
    "\\end{align*}\n",
    "\n",
    "which is sometimes called the *soft-max operator* and converges as $T\\rightarrow0$ toward\n",
    "\n",
    "\\begin{align*}\n",
    "\\max_{y\\in\\mathcal{Y}}\\left\\{  U_{y},0\\right\\}  .\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: the generalized extreme value (GEV) class\n",
    "\n",
    "Let $\\mathbf{F}$ be a cumulative distribution such that function $g$ defined by\n",
    "\n",
    "\\begin{align*}\n",
    "g\\left(  x_{1},...,x_{n}\\right)  =-\\log\\mathbf{F}\\left(  -\\log x_{1},...,-\\log\n",
    "x_{n}\\right)  \\label{cdfGEV}\n",
    "\\end{align*}\n",
    "\n",
    "is positive homogeneous of degree $1$. (This inverts into $\\mathbf{F}\\left(u_{1},...,u_{n}\\right)  =\\exp\\left(  -g\\left(  e^{-u_{1}},...,e^{-u_{n} }\\right)  \\right)  $). We have by a theorem of McFadden (1978):\n",
    "\n",
    "---\n",
    "**Theorem** \n",
    "\n",
    "Let $\\left(  \\varepsilon_{y}\\right)  _{1\\leq y\\leq n}$ be a random vector with c.d.f. $\\mathbf{F}$, and define\n",
    "\n",
    "\\begin{align*}\n",
    "Z=\\max_{y=1,...,n}\\left\\{  U_{y}+\\varepsilon_{y}\\right\\}  .\n",
    "\\end{align*}\n",
    "\n",
    "Then $Z$ has the same distribution as $\\log g\\left(  e^{U_{1}},...,e^{U_{n}}\\right)  +\\gamma+\\epsilon$, where $\\epsilon$ is a standard Gumbel. In particular,\n",
    "\\begin{align*}\n",
    "\\mathbb{E}\\left[  \\max_{y=1,...,n}\\left\\{  U_{y}+\\varepsilon_{y}\\right\\}\n",
    "\\right]  =\\log g\\left(  e^{U_{1}},...,e^{U_{n}}\\right)  +\\gamma\n",
    "\\end{align*}\n",
    "where $\\gamma$ is the Euler constant $\\gamma\\simeq0.5772$.\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "**Proof**\n",
    "\n",
    "Let $F_{Z}$ be the c.d.f. of $Z=\\max_{y=1,\\ldots,n}\\left\\{  U_{y}+\\varepsilon_{y}\\right\\}  $. One has \n",
    "\n",
    "\\begin{align*}\n",
    "F_{Z}\\left(  z\\right)   &  =\\Pr\\left(  \\max_{y=1,\\ldots,n}\\left\\{\n",
    "U_{y}+\\varepsilon_{y}\\right\\}  \\leq z\\right)  =\\Pr\\left(  \\forall\n",
    "y:~\\varepsilon_{y}\\leq z-U_{y}\\right) \\\\\n",
    "&  =\\mathbf{F}\\left(  z-U_{1},...,z-U_{n}\\right)  =\\exp\\left(  -g\\left(\n",
    "e^{U_{1}-z},...,e^{U_{n}-z}\\right)  \\right) \\\\\n",
    "&  =\\exp\\left(  -e^{-z}g\\left(  e^{U_{1}},...,e^{U_{n}}\\right)  \\right)\n",
    "=\\varphi\\left(  z-\\log g\\left(  e^{U_{1}},...,e^{U_{n}}\\right)  -\\gamma\n",
    "\\right)\n",
    "\\end{align*}\n",
    "\n",
    "where $\\varphi\\left(  z\\right)  :=\\exp\\left(  -e^{-\\left(  z-\\gamma\\right) }\\right)  $ is the cdf of the standard Gumbel distribution. Hence $Z$ has the distribution of $\\log g\\left(  e^{U_{1}},...,e^{U_{n}}\\right)  +\\gamma +\\epsilon$, where $\\epsilon$ is a standard Gumbel.\n",
    "\n",
    "---\n",
    "\n",
    "As a result, the choice probability of alternative $y$ is\n",
    "\n",
    "\\begin{align*}\n",
    "\\sigma_{y}\\left(  U\\right)  =\\frac{\\frac{\\partial g}{\\partial x_{y}}\\left(e^{U_{1}},...,e^{U_{n}}\\right)  }{g\\left(  e^{U_{1}},...,e^{U_{n}}\\right)\n",
    "}e^{U_{y}}.\n",
    "\\end{align*}\n",
    "\n",
    "The GEV\\ framework has several commonly used examples: logit, nested logit, mixture of logit...\n",
    "\n",
    "We just saw the logit model, in which $g\\left(  x_{1},...,x_{n}\\right) =e^{-\\gamma}\\sum_{y=1}^{n}x_{y}$. In this case, the distribution of\n",
    "\n",
    "\\begin{align*}\n",
    "Z=\\max_{y=1,\\ldots,n}\\left\\{  U_{y}+\\varepsilon_{y}\\right\\}\n",
    "\\end{align*}\n",
    "\n",
    "is $\\log\\sum_{y=1}^{n}e^{U_{y}}+\\epsilon$, where $\\epsilon$ is a standard Gumbel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: nested logit model\n",
    "\n",
    "The nested logit model is an instance of GEV model where alternatives can be grouped in nests. Eg, people choose their means of transportation (nest), and within this nest, a particular operator.\n",
    "\n",
    "\\Let $\\mathcal{X}$ be the set of nests and assume that for each nest $x$, there is a set $\\mathcal{Y}_{x}$ alternatives. Let $U_{xy}$ be utility from alternative $y$ in nest $x$, and $\\lambda_{x}\\in\\left[  0,1\\right]  $ and\n",
    "\n",
    "\\begin{align*}\n",
    "g\\left(  U_{xy}\\right)  =e^{-\\gamma}\\sum_{x\\in\\mathcal{X}}\\left(  \\sum\n",
    "_{y\\in\\mathcal{Y}_{x}}U_{xy}^{1/\\lambda_{x}}\\right)  ^{\\lambda_{x}}.\n",
    "\\end{align*}\n",
    "\n",
    "In this case,\n",
    "\n",
    "\\begin{align*}\n",
    "G\\left(  U\\right)   &  =\\mathbb{E}\\left[  \\max_{x\\in\\mathcal{X}}\\max\n",
    "_{y\\in\\mathcal{Y}_{x}}\\left\\{  U_{xy}+\\varepsilon_{xy}\\right\\}  \\right] \\\\\n",
    "&=\\log\\sum_{x\\in\\mathcal{X}}\\left(  \\sum_{y\\in\\mathcal{Y}_{x}}e^{U_{xy}/\\lambda_{x}}\\right)  ^{\\lambda_{x}}\\\\\n",
    "\\sigma_{xy}\\left(  U\\right)   &  =\\frac{\\left(  \\sum_{y\\in\\mathcal{Y}_{x}}e^{U_{xy}/\\lambda_{x}}\\right)  ^{\\lambda_{x}}}{\\sum_{x\\in\\mathcal{X}}\\left(\\sum_{y\\in\\mathcal{Y}_{x}}e^{U_{xy}/\\lambda_{x}}\\right)  ^{\\lambda_{x}}}\\frac{e^{U_{xy}/\\lambda_{x}}}{\\left(  \\sum_{y\\in\\mathcal{Y}_{x}}e^{U_{xy}/\\lambda_{x}}\\right)}\n",
    "\\end{align*}\n",
    "\n",
    "so the demand map has an interesting interpretation as \"choice of nest then choice of alternative\".\n",
    "\n",
    "Assume that $\\left(  \\varepsilon_{1},\\varepsilon_{2}\\right)  $ have a nested logit distribution with two nests, that is, their cdf is given by \n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{F}\\left(  u_{1},u_{2}\\right)  =\\exp\\left(  -e^{-\\gamma}\\left(e^{-u_{1}/\\lambda}+e^{-u_{2}/\\lambda}\\right)  ^{\\lambda}\\right)  .\n",
    "\\end{align*}\n",
    "\n",
    "Particular cases:\n",
    "\n",
    "* When $\\lambda=1$, $\\varepsilon_{1}$ and $\\varepsilon_{2}$ are independent and one recovers the logit model.\n",
    "\n",
    "* When $\\lambda\\rightarrow0$, $\\mathbf{F}\\left(  u_{1},u_{2}\\right) =\\exp\\left(  -e^{-\\gamma}e^{\\max\\left\\{  -u_{1},-u_{2}\\right\\}  }\\right)=\\min\\left\\{  \\mathbf{F}\\left(  u_{1}\\right)  ,\\mathbf{F}\\left(  u_{2}\\right) \\right\\}  $ and therefore $\\varepsilon_{1}$ and $\\varepsilon_{2}$ are perfectly correlated.\n",
    "\n",
    "In general one can show that\n",
    "\n",
    "\\begin{align*}\n",
    "\\lambda=\\sqrt{1-cor\\left(  \\varepsilon_{1},\\varepsilon_{2}\\right)  }%\n",
    "\\end{align*}\n",
    "\n",
    "This formula, due to Tiago de Oliviera, is not straightforward to prove and is the object of an optional problem set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other popular examples\n",
    "\n",
    "* Probit model (later)\n",
    "\n",
    "* Berry-Pakes' pure characteristics model (later)\n",
    "\n",
    "* Berry-Levinsohn-Pakes' mixed logit coefficient model (later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demand inversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many settings, the econometrician observes the market shares $s_{y}$ and wants to deduce the corresponding vector of systematic utilities. That is, we would like to solve:\n",
    "\n",
    "---\n",
    "**Problem**. \n",
    "\n",
    "Given a vector $s$ with positive entries satisfying $\\sum_{y\\in\\mathcal{Y}}s_{y}<1$, characterize and compute the set\n",
    "\n",
    "\\begin{align*}\n",
    "\\sigma^{-1}\\left(  s\\right)  =\\left\\{  U\\in\\mathbb{R}^{\\mathcal{Y}}%\n",
    ":\\sigma\\left(  U\\right)  =s\\right\\}  .\n",
    "\\end{align*}\n",
    "\n",
    "---\n",
    "\n",
    "This problem is called \"demand inversion\", or \"conditional choice\n",
    "probability inversion\", or \"identification problem\". It is a central issue in econometrics/industrial organization and will be a key building block for matching models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demand inversion via convex analysis\n",
    "\n",
    "We saw in Lecture $3$ how to invert gradient of convex functions: if $G$ is strictly convex and $C^{1}$, then\n",
    "\n",
    "\\begin{align*}\n",
    "\\sigma^{-1}\\left(  s\\right)  =\\nabla G^{-1}(s)=\\nabla G^{\\ast}\\left(\n",
    "s\\right)  .\n",
    "\\end{align*}\n",
    "\n",
    "$G^{\\ast}$ is the Legendre-Fenchel transform of $G$; we call it the *entropy of choice*, defined by\n",
    "\n",
    "\\begin{align*}\n",
    "G^{\\ast}(s)=\\max_{U}\\left\\{  \\sum_{y\\in\\mathcal{Y}}s_{y}U_{y}-G(U)\\right\\}.\n",
    "\\label{eq:constrG}%\n",
    "\\end{align*}\n",
    "\n",
    "Hence, $\\sigma^{-1}\\left(  s\\right)  $ is the vector $U$ such that\n",
    "\n",
    "\\begin{align*}\n",
    "U\\in\\arg\\max_{U}\\left\\{  \\sum_{y\\in\\mathcal{Y}}s_{y}U_{y}-G(U)\\right\\} .\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy of choice\n",
    "\n",
    "Convex duality implies that if $s$ and $U$ are related by $s\\in\\partial G\\left(  U\\right)$, then\n",
    "\n",
    "\\begin{align*}\n",
    "G(U)=\\sum_{y\\in\\mathcal{Y}}s_{y}U_{y}-G_{x}^{\\ast}(s). \\label{fenchel}%\n",
    "\\end{align*}\n",
    "\n",
    "But letting $Y=\\arg\\max_{y}\\left\\{  U_{y}+\\varepsilon_{y}\\right\\}$, $G\\left(  U\\right)  =\\mathbb{E}\\left[  U_{Y}+\\varepsilon_{Y}\\right]$ implies\n",
    "\n",
    "\\begin{align*}\n",
    "G(U)=\\sum_{y\\in\\mathcal{Y}}s_{y}U_{y}+\\mathbb{E}\\left[  \\varepsilon\n",
    "_{Y}\\right]  ,\n",
    "\\end{align*}\n",
    "\n",
    "thus one has\n",
    "\n",
    "\\begin{align*}\n",
    "G^{\\ast}(s)=-\\mathbb{E}\\left[  \\varepsilon_{Y}\\right]  . \\label{Fenchel}%\n",
    "\\end{align*}\n",
    "\n",
    "Hence, the entropy of choice $G^{\\ast}\\left(  s\\right)  $ is interpreted as minus\\ the expected amount of heterogeneity needed to rationalize the choice probabilities $s$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: entropy of choice and identification, logit model\n",
    "\n",
    "Then\n",
    "\n",
    "\\begin{align*}\n",
    "G^{\\ast}\\left(  s\\right)  =s_{0}\\log(s_{0})+\\sum_{y\\in\\mathcal{Y}}s_{y}\\log s_{y}\n",
    "\\end{align*}\n",
    "\n",
    "where $s_{0}=1-\\sum_{y\\in\\mathcal{Y}}s_{y}$. Hence, $G^{\\ast}$ is a bona fide entropy function when $\\mathbf{P}$ is Gumbel--hence the name of *entropy  of choice* in general.\n",
    "\n",
    "As a result,\n",
    "\n",
    "\\begin{align*}\n",
    "\\sigma_{y}^{-1}\\left(  s\\right)  =\\log\\frac{s_{y}}{s_{0}}\n",
    "\\end{align*}\n",
    "\n",
    "which is the celebrated *log-odds ratio formula*: the log of the odds of alternatives $y$ and $0$ identify the difference between the systematic utilities of these alternatives.\n",
    "\n",
    "The entropy of choice $G^{\\ast}$ in the nested logit model is given by\n",
    "\n",
    "\\begin{align*}\n",
    "G^{\\ast}\\left(  s\\right)  =\\sum_{x\\in\\mathcal{X}}\\sum_{y\\in\\mathcal{Y}_{x}}\\lambda_{x}s_{xy}\\ln s_{xy}+\\sum_{x\\in\\mathcal{X}}\\left(  1-\\lambda_{x}\\right)  \\left(  \\sum_{z\\in\\mathcal{Y}_{x}}s_{xz}\\right)  \\ln\\left(\\sum_{z\\in\\mathcal{Y}_{x}}s_{xz}\\right)  \\label{Gstarnestedlogit}\n",
    "\\end{align*}\n",
    "\n",
    "if $s_{xy}\\geq0$ and $\\sum_{x\\in\\mathcal{X}}\\sum_{y\\in\\mathcal{Y}_{x}}s_{xy}=1$, $G^{\\ast}\\left(  s\\right)  =+\\infty$ otherwise.\n",
    "\n",
    "Identification in the nested logit model: with normalization $\\sum _{x\\in\\mathcal{X}}\\left(  \\sum_{y\\in\\mathcal{Y}_{x}}e^{U_{xy}/\\lambda_{x}}\\right)  ^{\\lambda_{x}}=1$, one has $s_{xy}=\\left(  \\sum_{y\\in\\mathcal{Y}_{x}}e^{U_{xy}/\\lambda_{x}}\\right)  ^{\\lambda_{x}-1}e^{U_{xy}/\\lambda_{x}}$, thus $\\sum_{y\\in\\mathcal{Y}_{x}}e^{U_{xy}/\\lambda_{x}}=\\left(  \\sum _{y\\in\\mathcal{Y}_{x}}s_{xy}\\right)  ^{1/\\lambda_{x}}$, therefore\n",
    "\n",
    "\\begin{align*}\n",
    "U_{xy}=\\lambda_{x}\\log s_{xy}-\\left(  \\lambda_{x}-1\\right)  \\log\\sum\n",
    "_{y\\in\\mathcal{Y}_{x}}s_{xy}.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is taken from Greene and Hensher (1997). 210 individuals are surveyed about their choice of travel mode between Sydney, Canberra and Melbourne, and the various costs (time and money) associated with each alternative. Therefore there are 840 = 4 x 210 observations, which we can stack into `travelmodedataset` a 3 dimensional array whose dimensions are mode,individual,dummy for choice+covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>individual</th><th scope=col>mode</th><th scope=col>choice</th><th scope=col>wait</th><th scope=col>vcost</th><th scope=col>travel</th><th scope=col>gcost</th><th scope=col>income</th><th scope=col>size</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>  1  </td><td>air  </td><td>no   </td><td>69   </td><td> 59  </td><td> 100 </td><td> 70  </td><td>35   </td><td>1    </td></tr>\n",
       "\t<tr><td>  1  </td><td>train</td><td>no   </td><td>34   </td><td> 31  </td><td> 372 </td><td> 71  </td><td>35   </td><td>1    </td></tr>\n",
       "\t<tr><td>  1  </td><td>bus  </td><td>no   </td><td>35   </td><td> 25  </td><td> 417 </td><td> 70  </td><td>35   </td><td>1    </td></tr>\n",
       "\t<tr><td>  1  </td><td>car  </td><td>yes  </td><td> 0   </td><td> 10  </td><td> 180 </td><td> 30  </td><td>35   </td><td>1    </td></tr>\n",
       "\t<tr><td>  2  </td><td>air  </td><td>no   </td><td>64   </td><td> 58  </td><td>  68 </td><td> 68  </td><td>30   </td><td>2    </td></tr>\n",
       "\t<tr><td>  2  </td><td>train</td><td>no   </td><td>44   </td><td> 31  </td><td> 354 </td><td> 84  </td><td>30   </td><td>2    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{lllllllll}\n",
       " individual & mode & choice & wait & vcost & travel & gcost & income & size\\\\\n",
       "\\hline\n",
       "\t   1   & air   & no    & 69    &  59   &  100  &  70   & 35    & 1    \\\\\n",
       "\t   1   & train & no    & 34    &  31   &  372  &  71   & 35    & 1    \\\\\n",
       "\t   1   & bus   & no    & 35    &  25   &  417  &  70   & 35    & 1    \\\\\n",
       "\t   1   & car   & yes   &  0    &  10   &  180  &  30   & 35    & 1    \\\\\n",
       "\t   2   & air   & no    & 64    &  58   &   68  &  68   & 30    & 2    \\\\\n",
       "\t   2   & train & no    & 44    &  31   &  354  &  84   & 30    & 2    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| individual | mode | choice | wait | vcost | travel | gcost | income | size |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "|   1   | air   | no    | 69    |  59   |  100  |  70   | 35    | 1     |\n",
       "|   1   | train | no    | 34    |  31   |  372  |  71   | 35    | 1     |\n",
       "|   1   | bus   | no    | 35    |  25   |  417  |  70   | 35    | 1     |\n",
       "|   1   | car   | yes   |  0    |  10   |  180  |  30   | 35    | 1     |\n",
       "|   2   | air   | no    | 64    |  58   |   68  |  68   | 30    | 2     |\n",
       "|   2   | train | no    | 44    |  31   |  354  |  84   | 30    | 2     |\n",
       "\n"
      ],
      "text/plain": [
       "     individual mode  choice wait vcost travel gcost income size\n",
       "[1,]   1        air   no     69    59    100    70   35     1   \n",
       "[2,]   1        train no     34    31    372    71   35     1   \n",
       "[3,]   1        bus   no     35    25    417    70   35     1   \n",
       "[4,]   1        car   yes     0    10    180    30   35     1   \n",
       "[5,]   2        air   no     64    58     68    68   30     2   \n",
       "[6,]   2        train no     44    31    354    84   30     2   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "thePath = getwd()\n",
    "travelmodedataset = as.matrix(read.csv(paste0(thePath, \"/../data_mec_optim/demand_travelmode/travelmodedata.csv\"), sep = \",\", \n",
    "    header = TRUE))  # loads the data\n",
    "head(travelmodedataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert strings to categorical variables\n",
    "convertmode = Vectorize(function(inputtxt) {\n",
    "    if (inputtxt == \"air\") {\n",
    "        return(1)\n",
    "    }\n",
    "    if (inputtxt == \"train\") {\n",
    "        return(2)\n",
    "    }\n",
    "    if (inputtxt == \"bus\") {\n",
    "        return(3)\n",
    "    }\n",
    "    if (inputtxt == \"car\") {\n",
    "        return(4)\n",
    "    }\n",
    "})\n",
    "convertchoice = function(x) (ifelse(x == \"no\", 0, 1))\n",
    "travelmodedataset[, 2] = convertmode(travelmodedataset[, 2])\n",
    "travelmodedataset[, 3] = convertchoice(travelmodedataset[, 3])\n",
    "\n",
    "# Useful things\n",
    "nobs = dim(travelmodedataset)[1]\n",
    "nind = nobs/4\n",
    "ncols = dim(travelmodedataset)[2]\n",
    "travelmodedataset = array(as.numeric(travelmodedataset), dim = c(4, nind, ncols))\n",
    "choices = travelmodedataset[, , 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we compute the unconditional market shares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Market shares:\"\n",
      "      air     train       bus       car \n",
      "0.2761905 0.3000000 0.1428571 0.2809524 \n"
     ]
    }
   ],
   "source": [
    "s = apply(X = choices, FUN = mean, MARGIN = 1)\n",
    "names(s) = c(\"air\", \"train\", \"bus\", \"car\")\n",
    "print(\"Market shares:\")\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define \"car\" as the default alternative. The utilities in the logit model are obtained by the log-odds ratio formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Systematic utilities (logit):\"\n",
      "        air       train         bus         car \n",
      "-0.01709443  0.06559728 -0.67634006  0.00000000 \n"
     ]
    }
   ],
   "source": [
    "Ulogit = log(s[1:4]/s[4])\n",
    "print(\"Systematic utilities (logit):\")\n",
    "print(Ulogit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute these utilities using a nested logit model with two nests, \"noncar\" and \"car\", and taking $\\lambda=0.5$ in both nests. Do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Systematic utilities (nested logit):\"\n",
      "      air     train       bus       car \n",
      "0.4613240 0.5026698 0.1317012 0.0000000 \n",
      "[1] \"Choice probabilities within nocar nest (predicted vs observed):\"\n",
      "      air     train       bus \n",
      "0.3841060 0.4172185 0.1986755 \n",
      "      air     train       bus \n",
      "0.3841060 0.4172185 0.1986755 \n",
      "[1] \"Choice probabilities of car nest (predicted vs observed):\"\n",
      "[1] 0.2809524\n",
      "[1] 0.2809524\n"
     ]
    }
   ],
   "source": [
    "lambda = c(1/2, 1/2)\n",
    "\n",
    "Unocar = lambda[1] * log(s[1:3]) + (1 - lambda[1]) * log(sum(s[1:3]))\n",
    "Ucar = lambda[2] * log(s[4]) + (1 - lambda[2]) * log(sum(s[4]))\n",
    "Unested = c(Unocar, Ucar) - Ucar\n",
    "print(\"Systematic utilities (nested logit):\")\n",
    "print(Unested)\n",
    "\n",
    "print(\"Choice probabilities within nocar nest (predicted vs observed):\")\n",
    "print(exp(Unested[1:3]/lambda[1])/sum(exp(Unested[1:3]/lambda[1])))\n",
    "print(s[1:3]/sum(s[1:3]))\n",
    "\n",
    "print(\"Choice probabilities of car nest (predicted vs observed):\")\n",
    "print(1/(sum(exp(Unested[1:3]/lambda[1]))^lambda[1] + 1))\n",
    "print(unname(s[4]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
