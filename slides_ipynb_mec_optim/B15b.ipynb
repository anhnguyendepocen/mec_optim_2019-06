{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Block 15: Rank constrained models</center>\n",
    "### <center>Alfred Galichon (NYU)</center>\n",
    "## <center>`math+econ+code' masterclass on matching models, optimal transport and applications</center>\n",
    "<center>© 2018-2019 by Alfred Galichon. Support from NSF grant DMS-1716489 is acknowledged. James Nesbit contributed.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning objectives\n",
    "\n",
    "* Affinity matrix\n",
    "\n",
    "* Index models\n",
    "\n",
    "* Rank-constraint models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "* Becker (1973). \"A Theory of Marriage: Part I\". *JPE*.\n",
    "\n",
    "* [COQ] Chiappori, Oreffice and Quintana-Domeque (2012). \"Fatter Attraction: Anthropometric and Socioeconomic Matching on the Marriage Market\", *Journal of Political Economy*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation: estimating indices of attractiveness\n",
    "\n",
    "Chiappori, Oreffice and Quintana-Domeque [COQ] assume individuals match on a scalar \"index of attractiveness\", subsuming BMI, salary, education. Then the surplus function is\n",
    "\n",
    "\\begin{align*}\n",
    "\\Phi\\left(  x,y\\right)  =\\left(  \\sum_{k}\\zeta_{k}x_{k}\\right)  \\left(\\sum_{l}\\nu_{l}y_{l}\\right)\n",
    "\\end{align*}\n",
    "\n",
    "$\\zeta_{k}/\\zeta_{k^{\\prime}}$ and $\\nu_{l}/\\nu_{l^{\\prime}}$ are marginal rates of substitution: how much richer do men/women need to be in order to compensate an increase in Body Mass Index?\n",
    "\n",
    "This problem can be solves by looking for the vectors of weights $\\zeta$ and $\\nu$ such that the rank correlation of $\\zeta^{\\intercal}x$ and $\\nu^{\\intercal}y$ is maximal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A look at the data\n",
    "\n",
    "[COQ] look at the characteristics of married couples, in particular body mass index, wages, and education.\n",
    "\n",
    "According to [COQ]:\n",
    "> Men may compensate 1.3 additional units of BMI with a 1%-increase in wages, while women may compensate two BMI units with one year of education."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation of affinity matrix by convex optimization\n",
    "\n",
    "Recall\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathcal{W}\\left(  A\\right)  =\\max_{\\pi\\in\\mathcal{M}\\left(  P,Q\\right)  }\\int x^{\\prime}Ayd\\pi\\left(  x,y\\right)  -\\sigma\\int\\pi\\left(  x,y\\right) d\\pi\\left(  x,y\\right)  .\n",
    "\\end{align*}\n",
    "\n",
    "and note that\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial\\mathcal{W}\\left(  A\\right)  }{\\partial A_{ij}}=C_{ij}^{A}\n",
    "\\end{align*}\n",
    "\n",
    "We are therefore looking for the estimator $\\hat{A}$ of the true $A$ such that $\\partial\\mathcal{W}\\left(  A\\right)  /\\partial A_{ij}=\\hat{C}_{ij}$.\n",
    "\n",
    "Thus we shall estimate $A$ by $\\hat{A}$ the solution of\n",
    "\n",
    "\\begin{align*}\n",
    "\\min_{A}\\left\\{  \\mathcal{W}\\left(  A\\right)  -\\sum_{ij}A_{ij}\\hat{C}_{ij}\\right\\}\n",
    "\\end{align*}\n",
    "\n",
    "which is a nice and smooth convex minimization problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Several proposals\n",
    "\n",
    "Several proposal to estimate $\\zeta$ and $\\nu$:\n",
    "\n",
    "1. Becker (1973): use Hotelling's canonical correlation analysis\n",
    "\\begin{align*}\n",
    "\\max_{\\zeta,\\nu} \\mathbb{E}\\left[  \\zeta^{\\intercal}XY^{\\intercal}\\nu\\right],\n",
    "\\end{align*}\n",
    "which is unbiased if $\\left(  X,Y\\right)  $ is Gaussian. Can be biased outside that case, cf. Dupuy-Galichon (AES, 2015).\n",
    "\n",
    "2. Chiappori, Oreffice and Quintana-Domeque (JPE 2013): when $Y$ is 1-dimensional, regress $Y$ on $X$.\n",
    "\n",
    "3. Tervio (AER 2007): maximize Spearman's rank correlation\n",
    "\\begin{align*}\n",
    "\\max_{\\zeta,\\nu}\\mathbb{E}\\left[  F_{\\zeta^{\\intercal}X}\\left(  \\zeta^{\\intercal}X\\right)  F_{\\nu^{\\intercal}Y}\\left(  \\nu^{\\intercal}Y\\right)\\right]  ,\n",
    "\\end{align*}\n",
    "where $F_{\\zeta^{\\intercal}X}$ and $F_{\\nu^{\\intercal}Y}$ are the cdfs of $\\zeta^{\\intercal}X$ and $\\nu^{\\intercal}Y$ respectively.\n",
    "\n",
    "4. In the spirit of Han (JE 1987), maximize\n",
    "\\begin{align*}\n",
    "\\sum_{ij}\\left(  1\\left\\{  \\zeta^{\\intercal}X_{i}>\\zeta^{\\intercal}X_{j}\\right\\}  1\\left\\{  \\nu^{\\intercal}Y_{i}>\\nu^{\\intercal}Y_{j}\\right\\}+1\\left\\{  \\zeta^{\\intercal}X_{i}<\\zeta^{\\intercal}X_{j}\\right\\}  1\\left\\{\\nu^{\\intercal}Y_{i}<\\nu^{\\intercal}Y_{j}\\right\\}  \\right)\n",
    "\\end{align*}\n",
    "\n",
    "5. Dupuy-Galichon-Sun (2017): perform rank-constrained estimation of $\\Phi\\left(  x,y\\right)  =x^{\\prime}Ay$ using nuclear norm regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuclear norm\n",
    "\n",
    "Recall that any $d\\times d$ matrix $A$ has a singular value decomposition\n",
    "\n",
    "\\begin{align*}\n",
    "A=U\\Lambda V^{\\intercal}\n",
    "\\end{align*}\n",
    "\n",
    "where $U$ and $V$ are orthogonal matrices, and $\\Lambda=diag\\left(\\lambda_{1},\\dots,\\lambda_{d}\\right)  $ is diagonal with positive entries ordered in descending order, i.e. $\\lambda_{1}\\geq\\lambda_{2}\\geq \\dots\\geq\\lambda_{d}\\geq0$.\n",
    "\n",
    "Note:\n",
    "\n",
    "* $\\Lambda$ are the eigenvalues of $AA^{\\intercal}$, and also of $A^{\\intercal}A$.\n",
    "\n",
    "* If $A$ is symmetric positive, then $\\Lambda$ are the eigenvalues of $A$.\n",
    "\n",
    "* The rank of $A$ is the number of nonzero entries of $\\lambda$.\n",
    "\n",
    "The nuclear norm of $A$, denoted $\\left\\vert A\\right\\vert _{\\ast}$, is simply the L1 norm of $\\lambda$, that is\n",
    "\n",
    "\\begin{align*}\n",
    "\\left\\vert A\\right\\vert _{\\ast}=\\sum_{i=1}^{d}\\lambda_{i}.\n",
    "\\end{align*}\n",
    "\n",
    "Controlling for nuclear norm is a good proxy for controlling for rank.\n",
    "\n",
    "Further, the nuclear norm is convex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Sub)gradient of the nuclear norm\n",
    "\n",
    "The nuclear norm can be expressed as\n",
    "\n",
    "\\begin{align*}\n",
    "\\left\\vert A\\right\\vert _{\\ast}=\\max_{U,V\\in O_{d}}Tr\\left(  U^{\\intercal}AV\\right)\n",
    "\\end{align*}\n",
    "\n",
    "from which its gradient may be inferred (from the envelope theorem).\n",
    "\n",
    "In general, one can use the nuclear norm for problems of the type\n",
    "\n",
    "\\begin{align*}\n",
    "\\min_{A}W\\left(  A\\right)  +\\gamma\\left\\vert A\\right\\vert _{\\ast}\n",
    "\\end{align*}\n",
    "\n",
    "which will drive low-rank solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The proximal operator\n",
    "* Compare:\n",
    "    + Usual gradient descent step: $ x_{t+1}=x_{t}-\\epsilon\\nabla h\\left(  x_{t}\\right)$\n",
    "    + Proximal gradient descent step: $x_{t+1}=x_{t}-\\epsilon\\nabla h\\left(  x_{t+1}\\right) $ (implicit scheme)\n",
    "* Note that the first expression cannot be recast as a minimization problem, while the second one does. Indeed, the  second expression can be expressed as\n",
    "\\begin{align*}\n",
    "\tx_{t+1}∈prox_{εh}(x_{t})\n",
    "\\end{align*}\n",
    "where for a convex function f, the proximal operator is defined as\n",
    "\\begin{align*}\n",
    "\tprox_{f}(x)=argmin_{z}{f(z)+(1/2)‖z-x‖²}.\n",
    "\\end{align*}\n",
    "* The ability to recast the descent step as a minimization problem is very useful because it applies also when f is nonsmooth.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proximal gradient algorithm\n",
    "* Consider $\\min g\\left(  x\\right)  +h\\left(  x\\right)$, where $g$ is convex and differentiable, and $h$ is convex and possibly nonsmooth.\n",
    "     + Standard gradient descent: $x_{t+1}=x_{t}-\\epsilon\\nabla g\\left(x_{t}\\right)  -\\epsilon\\nabla h\\left(  x_{t}\\right)  $\n",
    "     + Proximal gradient descent: $x_{t+1}=x_{t}-\\epsilon\\nabla g\\left(\n",
    "x_{t}\\right)  -\\epsilon\\nabla h\\left(  x_{t+t}\\right)  $. \n",
    "\n",
    "* Proximal gradient descent thus amounts to doing $x_{t+1}+\\epsilon\\nabla h\\left(  x_{t+1}\\right)  =x_{t}-\\epsilon\\nabla\n",
    "g\\left(  x_{t}\\right)  $, or in other words \n",
    "\\begin{align*}\n",
    "x_{t+1}=prox_{\\epsilon h}\\left(  x_{t}-\\epsilon\\nabla g\\left(  x_{t}\\right)\\right)\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to estimate our low rank affinity matrix. We will look to perform proximal gradient descent with nuclear norm regularization, to find the low rank affinity matrix that best approximates the matching in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "affinity = function(Xvals, Yvals, sigma = 1, lambda = 1) {\n",
    "    phis = kronecker(t(Yvals), t(Xvals))\n",
    "    dX = dim(Xvals)[2]\n",
    "    dY = dim(Yvals)[2]\n",
    "    n = dim(Xvals)[1]\n",
    "    if (n != dim(Yvals)[1]) {\n",
    "        stop(\"Dimensions of Xvals and Yvals do not match.\")\n",
    "    }\n",
    "    \n",
    "    p = rep(1/n, n)\n",
    "    q = rep(1/n, n)\n",
    "    IX = rep(1, n)\n",
    "    tIY = matrix(rep(1, n), nrow = 1)\n",
    "    f = p %*% tIY\n",
    "    g = IX %*% t(q)\n",
    "    pihat = diag(n)/n\n",
    "    v = rep(0, n)\n",
    "    \n",
    "    A = rep(0, dX * dY)\n",
    "    t_k = 0.3  # step size for the prox grad algorithm (or grad descent when lambda=0)\n",
    "    \n",
    "    iterCount = 0\n",
    "    \n",
    "    while (1) {\n",
    "        # Compute pi_A\n",
    "        Phi = Xvals %*% matrix(A, nrow = dX) %*% t(Yvals)\n",
    "        contIpfp = TRUE\n",
    "        iterIpfp = 0\n",
    "        while (contIpfp) {\n",
    "            iterIpfp = iterIpfp + 1\n",
    "            u = sigma * log(apply(g * exp((Phi - IX %*% t(v))/sigma), 1, sum))\n",
    "            vnext = sigma * log(apply(f * exp((Phi - u %*% tIY)/sigma), 2, sum))\n",
    "            error = max(abs(apply(g * exp((Phi - IX %*% t(vnext) - u %*% tIY)/sigma), \n",
    "                1, sum) - 1))\n",
    "            if ((error < tolIpfp) | (iterIpfp >= maxiterIpfp)) {\n",
    "                contIpfp = FALSE\n",
    "            }\n",
    "            v = vnext\n",
    "        }\n",
    "        \n",
    "        pi = f * g * exp((Phi - IX %*% t(v) - u %*% tIY)/sigma)\n",
    "        \n",
    "        if (iterIpfp >= maxiterIpfp) {\n",
    "            stop(\"maximum number of iterations reached\")\n",
    "        }\n",
    "        \n",
    "        # do prox grad descent\n",
    "        thegrad = c(phis %*% c(pi - pihat))\n",
    "        \n",
    "        # take one gradient step\n",
    "        A = A - t_k * thegrad\n",
    "        \n",
    "        if (lambda > 0) \n",
    "            {\n",
    "                # compute the proximal operator\n",
    "                SVD = svd(matrix(A, nrow = dX))\n",
    "                U = SVD$u\n",
    "                D = SVD$d\n",
    "                V = SVD$v\n",
    "                \n",
    "                D = pmax(D - lambda * t_k, 0)\n",
    "                A = c(U %*% diag(D) %*% t(V))\n",
    "            }  # if lambda = 0 then we are just taking one step of gradient descent\n",
    "        \n",
    "        \n",
    "        ### testing optimality\n",
    "        if (iterCount%%10 == 0) {\n",
    "            alpha = 1\n",
    "            tmp = svd(matrix(A - alpha * thegrad, nrow = dX))\n",
    "            tmp_second = sum((A - c(tmp$u %*% diag(pmax(tmp$d - alpha * lambda, 0)) %*% \n",
    "                t(tmp$v)))^2)\n",
    "            cat(\"testing optimality \", tmp_second, \"\\n\")\n",
    "        }\n",
    "        \n",
    "        if (lambda > 0) {\n",
    "            theval = sum(thegrad * c(A)) - sigma * sum(pi * log(pi)) + lambda * sum(D)\n",
    "        } else {\n",
    "            theval = sum(thegrad * c(A)) - sigma * sum(pi * log(pi))\n",
    "        }\n",
    "        \n",
    "        iterCount = iterCount + 1\n",
    "        \n",
    "        if (iterCount > 1 && abs(theval - theval_old) < 1e-06) {\n",
    "            break\n",
    "        }\n",
    "        theval_old = theval   \n",
    "    }\n",
    "    return(list(A = matrix(A, nrow = dX), val = theval))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compute this for a fixed $\\lambda$. We could vary the value of $\\lambda$ using cross-validation to get the desired level of rank reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in file(file, \"rt\"):\n",
      "\"cannot open file 'DGS_low_rank_april16.csv': No such file or directory\""
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in file(file, \"rt\"): cannot open the connection\n",
     "output_type": "error",
     "traceback": [
      "Error in file(file, \"rt\"): cannot open the connection\nTraceback:\n",
      "1. read.csv(\"DGS_low_rank_april16.csv\")",
      "2. read.table(file = file, header = header, sep = sep, quote = quote, \n .     dec = dec, fill = fill, comment.char = comment.char, ...)",
      "3. file(file, \"rt\")"
     ]
    }
   ],
   "source": [
    "#thepath = paste0(getwd(),\"/../data_mec_optim/\")\n",
    "mydata <- read.csv(\"DGS_low_rank_april16.csv\")\n",
    "#Xvals = mydata[,c(1:22, 45:48)]\n",
    "#Yvals = mydata[,c(23:44, 56:59)]\n",
    "\n",
    "Xvals = mydata[,c(45:48)]\n",
    "Yvals = mydata[,c(56:59)]\n",
    "tolIpfp = 1e-12\n",
    "maxiterIpfp = 1000\n",
    "\n",
    "seed = 777\n",
    "set.seed(seed)\n",
    "\n",
    "# Standardize\n",
    "meanX = apply(Xvals, 2, mean)\n",
    "meanY = apply(Yvals, 2, mean)\n",
    "sdX = apply(Xvals, 2, sd)\n",
    "sdY = apply(Yvals, 2, sd)\n",
    "\n",
    "Xvals = t(t(Xvals) - meanX)\n",
    "Yvals = t(t(Yvals) - meanY)\n",
    "Xvals = t(t(Xvals)/sdX)\n",
    "Yvals = t(t(Yvals)/sdY)\n",
    "\n",
    "res = affinity(Xvals, Yvals, sigma=1, lambda=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td> 0.259367257</td><td> 0.019745466</td><td>-0.06198573 </td><td> 0.002713854</td></tr>\n",
       "\t<tr><td> 0.029096742</td><td> 0.002923766</td><td>-0.01160270 </td><td> 0.003663925</td></tr>\n",
       "\t<tr><td>-0.054458621</td><td>-0.007945686</td><td> 0.03794256 </td><td>-0.018583367</td></tr>\n",
       "\t<tr><td>-0.009374241</td><td> 0.003116353</td><td>-0.02288552 </td><td> 0.018058736</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{llll}\n",
       "\t  0.259367257 &  0.019745466 & -0.06198573  &  0.002713854\\\\\n",
       "\t  0.029096742 &  0.002923766 & -0.01160270  &  0.003663925\\\\\n",
       "\t -0.054458621 & -0.007945686 &  0.03794256  & -0.018583367\\\\\n",
       "\t -0.009374241 &  0.003116353 & -0.02288552  &  0.018058736\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "|  0.259367257 |  0.019745466 | -0.06198573  |  0.002713854 |\n",
       "|  0.029096742 |  0.002923766 | -0.01160270  |  0.003663925 |\n",
       "| -0.054458621 | -0.007945686 |  0.03794256  | -0.018583367 |\n",
       "| -0.009374241 |  0.003116353 | -0.02288552  |  0.018058736 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]         [,2]         [,3]        [,4]        \n",
       "[1,]  0.259367257  0.019745466 -0.06198573  0.002713854\n",
       "[2,]  0.029096742  0.002923766 -0.01160270  0.003663925\n",
       "[3,] -0.054458621 -0.007945686  0.03794256 -0.018583367\n",
       "[4,] -0.009374241  0.003116353 -0.02288552  0.018058736"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(A = res$A)\n",
    "val = res$val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "2"
      ],
      "text/latex": [
       "2"
      ],
      "text/markdown": [
       "2"
      ],
      "text/plain": [
       "[1] 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qr(A)$rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
